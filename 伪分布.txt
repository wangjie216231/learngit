查询是否安装java软件：
[atguigu@hadoop101 opt]$ rpm -qa | grep java
如果安装的版本低于1.7，卸载该jdk：
[atguigu@hadoop101 opt]$ sudo rpm -e 软件包
可以加 --nodeps 解除依赖 卸载sudo rpm -e --nodeps java-1.8.0-openjdk-1.8.0.181-7.b13.el7.x86_64  

创建用户：
useradd atguigu
passwd atguigu =====Changing password for user atguigu.



echo $JAVA_HOME

hadoop-env.sh
export JAVA_HOME=/opt/module/jdk1.8.0_144


core-site.xml
<!-- 指定HDFS中NameNode的地址 -->
<property>
	<name>fs.defaultFS</name>
    <value>hdfs://hadoop101:9000</value>
</property>
<!-- 指定hadoop运行时产生文件的存储目录 -->
<property>
	<name>hadoop.tmp.dir</name>
	<value>/opt/module/hadoop-2.7.2/data/tmp</value>
</property>



hdfs-site.xml

	
启动集群:
格式化NameNode
 bin/hdfs namenode -format
 
 启动NameNode
sbin/hadoop-daemon.sh start namenode

启动DataNode
sbin/hadoop-daemon.sh start datanode


namenode启动datanode 没启动:
删/home/hadoop/apps/dfs/data    ====数据GG
/home/hadoop/apps/dfs/name/current/VERSION  里面的clusterID
替换
/home/hadoop/apps/dfs/name/current/VERSION

查看集群
jps



查看产生的log日志
logs/
62595 DataNode
51076 DFSAdmin===============多任务工具，获取hdfs状态信息，可执行一些操作
62935 NodeManager
62999 Jps
62824 -- process information unavailable
62490 NameNode



思考：为什么不能一直格式化namenode，格式化namenode时，要注意什么？
删除data  和 logs 文件
/opt/module/hadoop-2.7.2/logs/hadoop-atguigu-datanode-hadoop101.out
opt/module/hadoop-2.7.2/data/tmp/dfs/name
opt/module/hadoop-2.7.2/data/tmp/dfs/data/current
\

opt/module/hadoop-2.7.2/data/tmp/dfs/data/current=================================
storageID=DS-c244a514-bea1-4b1d-abb7-58b56cc085aa
clusterID=CID-ed2b3db2-a80a-4803-98d7-b715296a0527
cTime=0
datanodeUuid=b068b39b-4dcd-4be5-81c6-da6f20dcd228
storageType=DATA_NODE
layoutVersion=-56

opt/module/hadoop-2.7.2/data/tmp/dfs/name:==============-================
clusterID=CID-ed2b3db2-a80a-4803-98d7-b715296a0527
cTime=0
storageType=NAME_NODE
blockpoolID=BP-898148531-192.168.126.101-1563243624432
layoutVersion=-63





创建文件夹  递归创建
bin/hdfs dfs -mkdir -p /user/atguigu/input

上传文件   上传
bin/hdfs dfs -put wcinput/wc.input（文件） /user/atguigu/input/     =====/user在哪？？

查看上传的文件是否正确   查看
bin/hdfs dfs -ls  /user/atguigu/input/
bin/hdfs dfs -cat  /user/atguigu/input/wc.input

运行mapreduce程序
bin/hadoop jar
share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input/(you /) /user/atguigu/output（wu/ 有也可以/）
进文件夹才有/，运行文件夹里面的所有东西可不加/
查看输出结果
bin/hdfs dfs -cat /user/atguigu/output/*(*)

测试文件内容下载到本地  下载
hadoop dfs -get /user/atguigu/output/part-r-00000 ./wcoutput/

删除结果  递归
hdfs dfs -rm -r /user/atguigu/output


配置集群  etc/hadoop/
配置yarn-env.sh
jdk

配置yarn-site.xml
<!-- reducer获取数据的方式 -->
<property>
 <name>yarn.nodemanager.aux-services</name>
 <value>mapreduce_shuffle</value>
</property>

<!-- 指定YARN的ResourceManager的地址 -->
<property>
<name>yarn.resourcemanager.hostname</name>
<value>hadoop101</value>
</property>


<!-- 日志聚集功能使能 -->
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
</property>
<!-- 日志保留时间设置7天 -->
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>604800</value>
</property>




配置：mapred-env.sh
jdk

配置： (对mapred-site.xml.template重新命名为) mapred-site.xml
<!-- 指定mr运行在yarn上 -->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>

 <!--配置历史服务器：-->
<property>
<name>mapreduce.jobhistory.address</name>
	<value>hadoop101:10020</value>
	</property>
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop101:19888</value>
</property>


启动集群
（a）启动前必须保证namenode和datanode已经启动
（b）启动resourcemanager
	sbin/yarn-daemon.sh start resourcemanager

（c）启动nodemanager
sbin/yarn-daemon.sh start nodemanager

http://hadoop101:8088

删除文件系统上的output文件
bin/hdfs dfs -rm -R /user/atguigu/output

执行mapreduce程序
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input  /user/atguigu/output
 
 查看运行结果，

 
 IDIDIDIDIDIDIDIDIDIDID两个
 
 
 配置历史服务器：
 mapred-site
<property>
<name>mapreduce.jobhistory.address</name>
	<value>hadoop101:10020</value>
	</property>
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop101:19888</value>
</property>


查看启动历史服务器文件目录
ls sbin/ | grep mr mr-jobhistory-daemon.sh
 
 启动历史服务器
 sbin/mr-jobhistory-daemon.sh start historyserver
 
 查看历史服务器是否启动
 jps
 
.sh 是sbin     其他bin


日志聚集概念：应用运行完成以后，将日志信息上传到HDFS系统上。都在YARN上面
yarn-site.xml

<!-- 日志聚集功能使能 -->
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
</property>
<!-- 日志保留时间设置7天 -->
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>604800</value>
</property>


2.关闭nodemanager 、resourcemanager和historymanager
sbin/yarn-daemon.sh stop resourcemanager
sbin/yarn-daemon.sh stop nodemanager
sbin/mr-jobhistory-daemon.sh stop historyserver

启动nodemanager 、resourcemanager和historymanager
sbin/yarn-daemon.sh start resourcemanager
sbin/yarn-daemon.sh start nodemanager
sbin/mr-jobhistory-daemon.sh start historyserver



配置文件说明
Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。
（1）默认配置文件：存放在hadoop相应的jar包中
[core-default.xml]
			hadoop-common-2.7.2.jar/ core-default.xml
		[hdfs-default.xml]
hadoop-hdfs-2.7.2.jar/ hdfs-default.xml
		[yarn-default.xml]
hadoop-yarn-common-2.7.2.jar/ yarn-default.xml
		[mapred-default.xml]
hadoop-mapreduce-client-core-2.7.2.jar/ mapred-default.xml
	（2）自定义配置文件：存放在$HADOOP_HOME/etc/hadoop
		core-site.xml
		hdfs-site.xml
		yarn-site.xml
		mapred-site.xml
		

删除命令：rm -rf  不提示

完全分布式
编写集群分发脚本xsync
scp:secure copy 安全拷贝
scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）
scp -r /opt/module/*  atguigu@hadoop102:/opt/module
scp -r atguigu@hadoop101:/opt/software atguigu@hadoop103:/opt/software    
rsync:不支持远程到远程的

rsync远程同步工具，主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。
rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。
rsync:不支持远程到远程的
scp 可以看到进程百分比


man rsync | more

rsync  -rvl        $pdir/$fname             $user@hadoop$host:$pdir

bash: xsync: command not found...问题
必须用root权限 chmod 777 xsync sudo也不行 
systemctl status rsyncd.service 
systemctl start rsyncd.service   
systemctl enable rsyncd.service 
yum install rsync -y




命令   命令参数    要拷贝的文件路径/名称    目的用户@主机:目的路径

-r	递归
-v	显示复制过程
-l	拷贝符号连接

rsync -rvl /opt/software/* hadoop102:/opt/software/
rsync:不支持远程到远程的
期望脚本：
在/home/atguigu/bin这个目录下存放的脚本，atguigu用户可以在系统任何地方直接执行。
xsync要同步的文件名称
/home/atguigu目录下创建bin目录，并在bin目录下xsync创建文件
/home/atguigu/bin   添加到、/etc/profile   PATH
		vi xsync
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=103; host<105; host++)); do
        echo --------------------- hadoop$host ----------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done

（2）修改脚本 xsync 具有执行权限
[atguigu@hadoop102 bin]$ chmod 777 xsync
（3）调用脚本形式：xsync 文件名称
[atguigu@hadoop102 bin]$ xsync /home/atguigu/bin

		hadoop102 		hadoop103			hadoop104
HDFS    NameNode  							SecondaryNameNode
		DataNode		DataNode    		DataNode
						
YARN	NodeManager		ResourceManager		NodeManager
						NodeManager	

什么节点启动什么服务，对应的

集群测试
1.	配置slaves  ==帮助namenode 识别datanode节点位置的。yarn启动也是通过slaves读取rousourcemanager
/opt/module/hadoop-2.7.2/etc/hadoop/slaves
[atguigu@hadoop102 hadoop]$ vi slaves
hadoop102
hadoop103
hadoop104						

50070
50090
19888
8080


生成公钥和私钥：
统一用户root就都是root，再atguigu同样走一遍流程1234
1、[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa   (每个主机都生成，且不同的用户也生成)
然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

/*2、将公钥拷贝到要免密登录的目标机器上===?????????需要吗
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104*/看情况

3、将103、104、的公钥添加到102的authorized_keys里面  
4、分发authorized_keys到所有节点服务器上
第一次登录需要密码，第二次就不需要了

Permission denied  许可拒绝

50070上 hadoop-2.7.2.tar.gz._COPYING_ 带后缀的都是未完成拷贝的

	    上传小文件
[atguigu@hadoop102 hadoop-2.7.2]$ hadoop dfs -mkdir -p /user/atguigu/input
[atguigu@hadoop102 hadoop-2.7.2]$ hadoop dfs -put wcinput/wc.input /user/atguigu/input
	    上传大文件
[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -put
 /opt/software/hadoop-2.7.2.tar.gz  /user/atguigu/input
（2）上传文件后查看文件存放在什么位置
	查看HDFS文件存储路径
[atguigu@hadoop102 subdir0]$ pwd
/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0

	查看HDFS在磁盘存储文件内容
[atguigu@hadoop102 subdir0]$ cat blk_1073741825
hadoop yarn
hadoop mapreduce 
atguigu
atguigu

（3）拼接
-rw-rw-r--. 1 atguigu atguigu 134217728 5月  23 16:01 blk_1073741836
-rw-rw-r--. 1 atguigu atguigu   1048583 5月  23 16:01 blk_1073741836_1012.meta
-rw-rw-r--. 1 atguigu atguigu  63439959 5月  23 16:01 blk_1073741837
-rw-rw-r--. 1 atguigu atguigu    495635 5月  23 16:01 blk_1073741837_1013.meta
[atguigu@hadoop102 subdir0]$ cat blk_1073741836>>tmp.file
[atguigu@hadoop102 subdir0]$ cat blk_1073741837>>tmp.file
[atguigu@hadoop102 subdir0]$ tar -zxvf tmp.file
（4）下载
[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -get
 /user/atguigu/input/hadoop-2.7.2.tar.gz ./

启动集群:
第一次启动格式化NameNode
 bin/hdfs namenode -format
 
 启动NameNode
sbin/hadoop-daemon.sh start namenode

启动DataNode
sbin/hadoop-daemon.sh start datanode


namenode启动datanode 没启动:
删/home/hadoop/apps/dfs/data    ====数据GG
/home/hadoop/apps/dfs/name/current/VERSION  里面的clusterID
替换
/home/hadoop/apps/dfs/name/current/VERSION
 
 
 
 
 启动停止，必须是同一用户的，root有服务不能在atguigu里面关掉，因为关不掉。
	（1）分别启动/停止hdfs组件
		hadoop-daemon.sh  start|stop  namenode|datanode|secondarynamenode
	（2）启动/停止yarn
		yarn-daemon.sh  start|stop  resourcemanager|nodemanager
2.	各个模块分开启动/停止（配置ssh是前提）常用
	（1）整体启动/停止hdfs
		sbin/start-dfs.sh
		sbin/stop-dfs.sh
	（2）整体启动/停止yarn
		sbin/start-yarn.sh
		sbin/stop-yarn.sh
start-all.sh====会对应的节点启动对应的服务，

 -- process information unavailable
 是因为进程虽然在内存中关闭了，但是Linux还会在/tmp下寻找这些临时文件，而此时临时文件并没有没正常删
rm -rf /tmp/hsperfdata_* 可以快速清除那些残留进程

core-site.xml里面配置错了</configuretion>可能关不掉secondarynamenode

You have new mail in /var/spool/mail/root =====？？？？？




1.	时间服务器配置（必须root用户）
（1）检查ntp是否安装
rpm -qa|grep ntp
ntp-4.2.6p5-10.el6.centos.x86_64
fontpackages-filesystem-1.41-1.1.el6.noarch
ntpdate-4.2.6p5-10.el6.centos.x86_64


systemctl status ntpdate.service
systemctl start ntpdate.service
systemctl enable ntpdate.service


没有:yum install ntpdate -y
yum install ntp -y
报错：Another app is currently holding the yum lock; waiting for it to exit.
	rm -f /var/run/yum.pid  ==强制关掉yum

（2）修改ntp配置文件
[root@hadoop102 桌面]# vi /etc/ntp.conf

修改内容如下；
a）修改1（授权192.168.1.0网段上的所有机器可以从这台机器上查询和同步时间）
	#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为
	restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap

b）修改2（集群在局域网中，不使用其他的网络时间）
	server 0.centos.pool.ntp.org iburst
	server 1.centos.pool.ntp.org iburst
	server 2.centos.pool.ntp.org iburst
	server 3.centos.pool.ntp.org iburst
	为
	#server 0.centos.pool.ntp.org iburst
	#server 1.centos.pool.ntp.org iburst
	#server 2.centos.pool.ntp.org iburst
	#server 3.centos.pool.ntp.org iburst
	
c）添加3（当该节点丢失网络连接，依然可以作为时间服务器为集群中的其他节点提供时间同步）
	server 127.127.1.0
	fudge 127.127.1.0 stratum 10
	
（3）修改/etc/sysconfig/ntpd 文件
	[root@hadoop102 桌面]# vim /etc/sysconfig/ntpd
	增加内容如下（让硬件时间与系统时间一起同步）
	SYNC_HWCLOCK=yes
	
（4）重新启动ntpd
	[root@hadoop102 桌面]# service ntpd status
	ntpd 已停
	[root@hadoop102 桌面]# service ntpd start
	正在启动 ntpd：     	[确定]
	
（5）执行：
	[root@hadoop102 桌面]# chkconfig ntpd on
	
	ntpd.service
	
	
2.	其他机器配置（必须root用户）
（1）在其他机器配置10分钟与时间服务器同步一次
	[root@hadoop103 hadoop-2.7.2]# crontab -e
	编写脚本
	*/10 * * * * /usr/sbin/ntpdate hadoop102
（2）修改任意机器时间
	[root@hadoop103 hadoop]# date -s "2017-9-11 11:11:11"
（3）十分钟后查看机器是否与时间服务器同步
	[root@hadoop103 hadoop]# date



5.1 前期准备工作
1.	CentOS联网 
	配置CentOS能连接外网。Linux虚拟机ping www.baidu.com 是畅通的
	注意：采用root角色编译，减少文件夹权限出现问题
2.	jar包准备(hadoop源码、JDK8、maven、ant 、protobuf)
（1）hadoop-2.7.2-src.tar.gz
（2）jdk-8u144-linux-x64.tar.gz
（3）apache-ant-1.9.9-bin.tar.gz（build工具，导包用的）
（4）apache-maven-3.0.5-bin.tar.gz
（5）protobuf-2.5.0.tar.gz（序列化的框架）
 (6) 安装  glibc-headers 和  g++  命令如下
 (7) 安装make和cmake

5.2 jar包安装
注意：所有操作必须在root用户下完成
	1.JDK解压、配置环境变量 JAVA_HOME和PATH，验证java-version(如下都需要验证是否配置成功)
	[root@hadoop101 software] # tar -zxf jdk-8u144-linux-x64.tar.gz -C /opt/module/
	[root@hadoop101 software]# vi /etc/profile
	#JAVA_HOME
	export JAVA_HOME=/opt/module/jdk1.8.0_144
	export PATH=$PATH:$JAVA_HOME/bin
	[root@hadoop101 software]#source /etc/profile
	验证命令：java -version



2.Maven解压、配置  MAVEN_HOME和PATH
	[root@hadoop101 software]# tar -zxvf apache-maven-3.0.5-bin.tar.gz -C /opt/module/
	[root@hadoop101 apache-maven-3.0.5]# vi conf/settings.xml
	<mirrors>
		<!-- mirror
		 | Specifies a repository mirror site to use instead of a given repository. The repository that
		 | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used
		 | for inheritance and direct lookup purposes, and must be unique across the set of mirrors.
		 |
	<mirror>
		   <id>mirrorId</id>
		   <mirrorOf>repositoryId</mirrorOf>
		   <name>Human Readable Name for this Mirror.</name>
		   <url>http://my.repository.com/repo/path</url>
		  </mirror>
		 -->
			<mirror>
					<id>nexus-aliyun</id>
					<mirrorOf>central</mirrorOf>
					<name>Nexus aliyun</name>
					<url>http://maven.aliyun.com/nexus/content/groups/public</url>
			</mirror>
			<mirror>
				   <id>mvnrepository</id>
				   <name>mvnrepository</name>
				   <url>http://central.maven.org/maven2/</url>
				   <mirrorOf>central</mirrorOf>
		   </mirror>
	  </mirrors>


	[root@hadoop101 apache-maven-3.0.5]# vi /etc/profile
	#MAVEN_HOME
	export MAVEN_HOME=/opt/module/apache-maven-3.0.5
	export PATH=$PATH:$MAVEN_HOME/bin

	[root@hadoop101 software]#source /etc/profile
	验证命令：mvn -version



3.ant解压、配置  ANT _HOME和PATH
	[root@hadoop101 software]# tar -zxvf apache-ant-1.9.9-bin.tar.gz -C /opt/module/
	[root@hadoop101 apache-ant-1.9.9]# vi /etc/profile

	#ANT_HOME
	export ANT_HOME=/opt/module/apache-ant-1.9.9
	export PATH=$PATH:$ANT_HOME/bin

	[root@hadoop101 software]#source /etc/profile
	验证命令：ant -version



4.安装  glibc-headers 和  g++  命令如下
	[root@hadoop101 apache-ant-1.9.9]# yum install glibc-headers
	[root@hadoop101 apache-ant-1.9.9]# yum install gcc-c++

5.安装make和cmake
	[root@hadoop101 apache-ant-1.9.9]# yum install make
	[root@hadoop101 apache-ant-1.9.9]# yum install 

6.解压protobuf ，进入到解压后protobuf主目录，/opt/module/protobuf-2.5.0，然后相继执行命令
	[root@hadoop101 software]# tar -zxvf protobuf-2.5.0.tar.gz -C /opt/module/
	[root@hadoop101 opt]# cd /opt/module/protobuf-2.5.0/

	[root@hadoop101 protobuf-2.5.0]#./configure 
	[root@hadoop101 protobuf-2.5.0]# make 
	[root@hadoop101 protobuf-2.5.0]# make check 
	[root@hadoop101 protobuf-2.5.0]# make install 
	[root@hadoop101 protobuf-2.5.0]# ldconfig 
	[root@hadoop101 hadoop-dist]# vi /etc/profile
	#LD_LIBRARY_PATH
	export LD_LIBRARY_PATH=/opt/module/protobuf-2.5.0
	export PATH=$PATH:$LD_LIBRARY_PATH
	[root@hadoop101 software]#source /etc/
	验证命令：protoc --version


7.安装openssl库
	[root@hadoop101 software]#yum install openssl-devel
	
8.安装 ncurses-devel库
	[root@hadoop101 software]#yum install ncurses-devel
	到此，编译工具安装基本完成。
	
5.3 编译源码   下午从这里开始
1.	解压源码到/opt/目录
	[root@hadoop101 software]# tar -zxvf hadoop-2.7.2-src.tar.gz -C /opt/
	
2.	进入到hadoop源码主目录
	[root@hadoop101 hadoop-2.7.2-src]# pwd
	/opt/hadoop-2.7.2-src
	
3.	通过maven执行编译命令
	[root@hadoop101 hadoop-2.7.2-src]#mvn package -Pdist,native -DskipTests -Dtar
等待时间30分钟左右，最终成功是全部SUCCESS，如图2-42所示。


4.	成功的64位hadoop包在/opt/hadoop-2.7.2-src/hadoop-dist/target下
	[root@hadoop101 target]# pwd
	/opt/hadoop-2.7.2-src/hadoop-dist/target
	
	
5.4 常见的问题及解决方案
1）MAVEN install时候JVM内存溢出
处理方式：在环境配置文件和maven的执行文件均可调整MAVEN_OPT的heap大小。（详情查阅MAVEN 编译 JVM调优问题，如：http://outofmemory.cn/code-snippet/12652/maven-outofmemoryerror-method）
2）编译期间maven报错。可能网络阻塞问题导致依赖库下载不完整导致，多次执行命令（一次通过比较难）：
[root@hadoop101 hadoop-2.7.2-src]#mvn package -Pdist,nativeN -DskipTests -Dtar
3）报ant、protobuf等错误，插件下载未完整或者插件版本问题，最开始链接有较多特殊情况，同时推荐
2.7.0版本的问题汇总帖子 http://www.tuicool.com/articles/IBn63qf
第6章 常见错误及解决方案
1）防火墙没关闭、或者没有启动yarnx
INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032
2）主机名称配置错误
3）ip地址配置错误
4）ssh没有配置好
5）root用户和atguigu两个用户启动集群不统一
6）配置文件修改不细心
7）未编译源码
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/22 15:38:58 INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032
8）datanode不被namenode识别问题
Namenode在format初始化的时候会形成两个标识，blockPoolId和clusterId。新的datanode加入时，会获取这两个标识作为自己工作目录中的标识。
一旦namenode重新format后，namenode的身份标识已变，而datanode如果依然持有原来的id，就不会被namenode识别。
解决办法，删除datanode节点中的数据后，再次重新格式化namenode。
9）不识别主机名称
java.net.UnknownHostException: hadoop102: hadoop102
        at java.net.InetAddress.getLocalHost(InetAddress.java:1475)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:146)
        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
        at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:415)
解决办法：
（1）在/etc/hosts文件中添加192.168.1.102 hadoop102
	（2）主机名称不要起hadoop  hadoop000等特殊名称
10）datanode和namenode进程同时只能工作一个。

11）执行命令	不生效，粘贴word中命令时，遇到-和长–没区分开。导致命令失效
解决办法：尽量不要粘贴word中代码。
12）jps发现进程已经没有，但是重新启动集群，提示进程已经开启。原因是在linux的根目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。
13）jps不生效。
原因：全局变量hadoop   java没有生效，需要source /etc/profile文件。
14）8088端口连接不上
[atguigu@hadoop102 桌面]$ cat /etc/hosts
注释掉如下代码
#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
#::1         hadoop102

hdfs-default.xml:
hadoop-2.7.2\share\doc\hadoop\hadoop-project-dist\hadoop-hdfs

core-default.xml:
share\doc\hadoop\hadoop-project-dist\hadoop-common

yarn-default.xml:
hadoop-2.7.2\share\doc\hadoop\hadoop-yarn\hadoop-yarn-common

mapred-default.xml:
hadoop-2.7.2\share\doc\hadoop\hadoop-mapreduce-client\hadoop-mapreduce-client-core





